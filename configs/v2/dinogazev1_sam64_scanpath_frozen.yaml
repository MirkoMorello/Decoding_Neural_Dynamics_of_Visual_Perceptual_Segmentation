#
# STAGE 3: Fine-tune the scanpath head on MIT1003 (saliency head frozen).
# FOLD 0
#

stage:
  kind: "mit_scanpath_frozen"
  name: "dinogaze_spade_v1_sam64_fold0"
  model_key: "dinogaze_spade_v1"
  dataset_key: "MIT1003"
  
  # --- Hyperparameters for this stage ---
  lr: 0.00005 # From your old lr_mit_scanpath_frozen
  milestones: [10, 20, 30, 35, 40]
  batch_size: 1
  grad_acc_steps: 4
  min_lr: 1.0e-7
  val_every: 1
  
  # --- CHECKPOINT CHAINING ---
  # Loads the model trained in the MIT spatial stage.
  resume_ckpt: "experiments/mit_spatial_finetune/dinogaze_spade_v1_sam64_fold0/step-0002.pth"

  # --- Model- and Data-specific parameters ---
  extra:
    # Model parameters
    requires_segmentation: true
    is_scanpath_stage: true             # Tells the builder to create a scanpath model
    freeze_saliency_network: true       # Tells the builder to freeze the saliency head
    included_fixations: [-1, -2, -3, -4] # Scanpath history length
    dino_model_name: 'dinov2_vitl14'
    dino_patch_size: 14
    dino_layers_for_main_path: [-3, -2, -1]
    dino_semantic_feature_layer_idx: -1
    num_total_segments: 64
    finalizer_initial_sigma: 8.0
    finalizer_learn_sigma: true
    
    # Data parameters for the MIT1003 builder
    fold: 0
    mask_dir: 'masks/mit1003/sam_vitl_k64_mit'

# --- Global Run Settings ---
compile: false
seed: 42
num_workers: 4

# --- Global Path Configuration ---
paths:
  dataset_dir: "./data/pysaliency_datasets"
  train_dir: "./experiments"
  lmdb_dir: "./data/lmdb_caches"