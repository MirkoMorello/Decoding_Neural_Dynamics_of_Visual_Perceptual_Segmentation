%-------------------------------------------------------------------
\chapter{Conclusions}
\label{c:conc}
%-------------------------------------------------------------------

\epigraph{\enquote{Computer Science is no more about computers than astronomy is about telescopes.}}{\emph{E. W. Dijkstra}}

This thesis embarked on an investigation into the fundamental relationship between visual scene segmentation and human gaze. Grounded in the theory that segmentation is an information-rich process that actively guides visual exploration, we sought to develop a new generation of computational gaze prediction models that explicitly leverage this information. This chapter summarizes the journey, synthesizes our principal findings, and outlines potential avenues for future work.

\section{Summary of Contributions}

We began by challenging the implicit nature of semantic understanding in existing state-of-the-art saliency models. While powerful, these models often treat the feature extractor as a black box. Our central contribution is a novel method for directly and efficiently injecting explicit segmentation information into a model's processing stream.

Through a series of carefully designed experiments, we progressed from an initial, successful but ambiguous, ViT-based model to our final \textbf{DinoGaze-SPADE} architecture. The key innovation was the development of a \enquote{semantic painting} technique, which creates a dynamic, feature-rich representation of a scene's segmentation map. This map, when used to modulate the network's activations via Spatially-Adaptive Normalization (SPADE), allowed us to isolate and confirm the significant contribution of segmentation information to gaze prediction, independent of general improvements in feature extraction.

\section{Principal Findings}

The empirical results presented in \cref{c:results} lead to three principal findings:

\begin{enumerate}
    \item \textbf{Vision Transformers provide a superior backbone for saliency modeling.} Our initial experiments showed that simply replacing the CNN backbone of a model like DeepGazeIII with a DINOv2 Vision Transformer yields a significant performance improvement. This establishes a new, stronger baseline for the field.
    
    \item \textbf{Dynamic SPADE is an effective mechanism for information injection.} Our core finding is that the direct injection of segmentation information via our dynamic SPADE mechanism provides a substantial performance boost on top of the already strong ViT backbone. This was validated through a series of ablation studies that ruled out alternative explanations, such as increased model complexity or the use of trivial embeddings. This result provides strong evidence for our central hypothesis: that explicit segmentation information can be exploited for more accurate gaze prediction.
    
    \item \textbf{The proposed architecture generalizes across tasks.} The performance benefits of the DinoGaze-SPADE model were not confined to static image saliency. The model also achieved state-of-the-art results on the more complex task of sequential scanpath prediction, demonstrating the fundamental and robust nature of our approach.
\end{enumerate}

\section{Future Work}

This work opens up several exciting avenues for future research.

\paragraph{Refining Segmentation Information.} Our model relies on segmentation maps generated by unsupervised methods. A promising direction would be to investigate the use of human-annotated segmentation data. Furthermore, the theoretical work that inspired this thesis deals with \emph{uncertainty} in segmentation. Future models could be designed to accept and utilize probabilistic segmentation maps, potentially leading to an even more nuanced and human-like understanding of a scene.

\paragraph{Exploring Other Top-Down Modalities.} The dynamic SPADE mechanism is a general tool for information injection. It could be adapted to modulate the network based on other forms of top-down information, such as task-specific instructions (e.g., \enquote{search for the car}) or high-level object labels, moving towards more comprehensive models of goal-directed attention.

\paragraph{Connecting to Neuroscience.} Our model offers a computationally explicit framework for how high-level semantic information (segmentation) can modulate visual processing. This framework could be used to generate testable hypotheses about the neural correlates of this process. Neuroimaging or electrophysiology studies could investigate whether brain activity in visual areas is modulated by segmentation in a way that is consistent with the SPADE mechanism.

\paragraph{Model Distillation and Application.} While our final model is efficient, the DINOv2 backbone is still large. For real-world applications, such as in human-computer interaction, user experience design, or automotive safety systems, future work could focus on distilling the knowledge of the DinoGaze-SPADE model into a smaller, faster architecture that can be deployed on edge devices.

In conclusion, this thesis has presented a novel and powerful architecture for gaze prediction. More importantly, it has provided strong empirical support for the theory that the segmentation of the visual world is not a separate, subsequent process, but is fundamentally intertwined with the dynamics of how and where we look.