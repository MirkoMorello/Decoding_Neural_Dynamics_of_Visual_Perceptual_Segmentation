%-------------------------------------------------------------------
\chapter{State of the Art}
\label{c:sota}
%-------------------------------------------------------------------

\epigraph{\enquote{The wireless telegraph is not difficult to understand. The ordinary telegraph is like a very long cat. You pull the tail in New York, and it meows in Los Angeles. The wireless is the same, only without the cat.}}{\emph{Albert Einstein}}

This chapter reviews the foundational concepts and prior work that form the basis of this thesis. We begin by defining the fundamental elements of human gaze behaviour before tracing the evolution of computational models designed to predict it. We will cover early bottom-up models, the transformative impact of deep learning, and provide a detailed analysis of DeepGaze III, the state-of-the-art model that serves as the primary benchmark and point of departure for our own contributions.

\section{Visual Fixations and Scanpaths}
\label{sec:sota_fixations}

The human visual system actively explores the environment through a continuous sequence of eye movements. This process is a sophisticated strategy to overcome the physical limitations of our eyes, which have a small, high-resolution central region called the \emph{fovea}, surrounded by a much larger, low-resolution periphery. To perceive a scene in detail, we must direct the fovea to points of interest. This behaviour is not static; it is highly dependent on the observer's task, as famously demonstrated by Yarbus \cite{yarbus1967eye}.

This exploration is achieved through two primary types of eye movements:
\begin{itemize}
    \item \textbf{Fixations:} Periods, typically lasting 200-300 milliseconds, during which the eye is held relatively still. This stability allows the visual system to gather detailed information from the foveated region.
    \item \textbf{Saccades:} Rapid, ballistic movements that shift the point of gaze from one fixation point to another. During a saccade, which can last from 30 to 120 milliseconds, visual sensitivity is suppressed.
\end{itemize}
The resulting sequence of fixations and saccades is known as a \textbf{scanpath}. The challenge of gaze prediction, as introduced in \cref{c:intro}, is to computationally model and predict these scanpaths.

\section{The Evolution of Saliency Models}
\label{sec:sota_evolution}

\subsection{Early Computational Models}
Early and highly influential work in computational modeling of attention was dominated by bottom-up, feature-driven approaches. The seminal model of Itti, Koch, and Niebur \cite{itti1998model} provided a computational implementation of Treisman's Feature Integration Theory. This model operates by first decomposing an input image into a set of low-level feature channels, such as color opponency (red-green, blue-yellow), intensity, and orientation at multiple spatial scales. 

For each feature, a \enquote{conspicuity map} is generated by identifying locations that stand out from their surroundings. These maps are then normalized and summed to create a single, master \textbf{saliency map}. This map represents the purely bottom-up, stimulus-driven \enquote{attractiveness} of each location. A winner-take-all network then selects the most salient location for the next fixation, and a mechanism called \enquote{inhibition of return} transiently suppresses the just-fixated location to encourage exploration of new areas.

\subsection{The Deep Learning Revolution}
With the advent of deep learning, the field of saliency prediction underwent a paradigm shift. Instead of relying on hand-crafted, low-level features, models began to leverage rich feature hierarchies learned by deep Convolutional Neural Networks (CNNs) pre-trained on large-scale object recognition datasets like ImageNet. This transfer learning approach massively boosted prediction performance \cite{kummerer2017understanding}.

Models like DeepGaze II \cite{kummerer2017understanding} became the new standard. DeepGaze II used a pre-trained VGG network as a frozen backbone to extract features and a small, learned readout network to transform these features into a spatial saliency map. This purely spatial model, which predicts the overall fixation density on an image, set the stage for its more sophisticated successor, DeepGaze III.

\subsection{The State of the Art: DeepGaze III}
\label{sec:sota_deepgaze3}

The direct predecessor and primary benchmark for our work is \textbf{DeepGaze III} \cite{kummerer2022deepgaze}, a state-of-the-art probabilistic model for predicting full human scanpaths. Unlike DeepGaze II, which only predicts spatial saliency, DeepGaze III is a generative model that captures the sequential dependency of fixations.

\paragraph{Architecture.} DeepGaze III employs a modular architecture, as detailed in the paper and shown in its Figure 2. It consists of three main components:
\begin{enumerate}
    \item A \textbf{Spatial Priority Network}, which uses a frozen DenseNet-201 backbone to extract deep image features, producing a \emph{spatial priority map} that encodes the image-driven relevance of each location.
    \item A \textbf{Scanpath Network}, which processes the viewing history. It takes the last four fixations and encodes them into a set of feature maps representing their location relative to every other point in the image (e.g., via Euclidean distance and coordinate differences).
    \item A \textbf{Fixation Selection Network}, which combines the output of the spatial and scanpath networks to produce the final prediction.
\end{enumerate}

\paragraph{Probabilistic Formulation.} Crucially, DeepGaze III is a probabilistic model. It does not just predict a single next fixation, but a full probability distribution over all possible next fixation locations. It models the conditional probability $p(f_i | f_{i-1}, ..., f_{i-4}, I)$, where $f_i$ is the current fixation and $I$ is the image. This allows the model to be trained using maximum likelihood and evaluated with rigorous information-theoretic metrics like Log-Likelihood (LL) and Information Gain (IG), as described in \cref{sec:sota_probabilistic_distinction}.

DeepGaze III established a new state of the art on the MIT1003 and MIT300 benchmarks. Its modularity also allows for ablation studies that can disentangle the relative contributions of image content versus scanpath history. However, its reliance on a CNN backbone and its method of combining the content and history streams present an opportunity for improvement, which is the central motivation for this thesis.
