{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>07/04/2025"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seminar of Flexible neural encoder architecture explains human high-level visual responses, Hossein Adeli, Cloumbia University"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Issue of moving instead of fixing in the center  \n",
    "fmri"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "super issue: they see the image 675 times, in their experiments they never see it and they see it only once, while in Ruben they see it too many times and they could be guessing.\n",
    "capsulnet expectation maximization, lower level capsule (transformer) 256x356 by 6, and you're saying are the lower level with diffeernt number of segments each of the them are routerd to ... and you get a certain segmentation map based on that.  \n",
    "slot attetnion, a certain attention that tries to learn to find the tokens...  \n",
    "the issue is that segmentation can't happen in the feature level everytime because in a higher level they are more similar, for example a vertical and a horizontal line, due to the spatial representation proximity and feature similarity.  \n",
    "similarity is not in the space of representation in transformers. find similarity not in the feature space.  \n",
    "familiarity mixed with a spatial prior can lead to an issue, it could explain the fact that the further away objects get a no question pretty quick.  \n",
    "in his experiments images appear only once and you have feedback for ecery rounds, and the dots are always at the fixation point and the other is somewhere else, they have ground truth, making it a very different task.  \n",
    "try to take a look at the reaction time during trials, they might go down a lot due to familiarity.  \n",
    "gaze at a module with deep gaze  \n",
    "scaled down saliency map of the image.  \n",
    "Do the examples make sens actually?  \n",
    "shorter saliency of 2 to 3 seconds  \n",
    "make sure they're aligned, some images make sense, other are concerning, usually people look at eyes for the first time  \n",
    "the way to downsizing the deep gaze you can diffues into surrounding area, check that. It could look worse but at least it doesn't look like a blob in the center.  \n",
    "_PSM, PSE and DGS, what are them? what do they give us?_  \n",
    "_What is the endgoal?_  \n",
    "segment by itself i very corase, saliency is different.  \n",
    "am i gonna use the segments to find the boudaries are?  \n",
    "_HOW DO SEGMENTS IMPACT OUR eye movements? it's too much of a hard question._  \n",
    "also remember that it seems like the attention is spreading.  \n",
    "(golom paper on two level... looking at aligment on different level)  \n",
    "we're working without ground truth, we don't know what a segment actually is, it's kind of different than an object but it's not fixed in place.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
